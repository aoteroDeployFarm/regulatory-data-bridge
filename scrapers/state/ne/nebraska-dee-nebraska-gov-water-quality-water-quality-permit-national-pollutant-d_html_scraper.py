# Auto-generated by generate_scrapers_from_json.py (HTML)
from __future__ import annotations
from pathlib import Path
import hashlib, json
from typing import Optional

# HTTP client selection
try:
    import httpx
    _HTTPX = True
except Exception:  # pragma: no cover
    _HTTPX = False
    import requests

from bs4 import BeautifulSoup

TARGET_URL = "https://dee.nebraska.gov/water-quality/water-quality-permitting/national-pollutant-discharge-elimination-systems-npdes-program"
CACHE_DIR = Path(__file__).parent / ".cache"
CACHE_DIR.mkdir(parents=True, exist_ok=True)
SIGNATURE_FILE = CACHE_DIR / "last_signature.json"
CONTENT_FILE = CACHE_DIR / "last_content.txt"

DEFAULT_SELECTOR = 'main, article, section, h1, h2, h3'

def _head(url: str):
    if _HTTPX:
        with httpx.Client(timeout=15.0, follow_redirects=True) as c:
            r = c.head(url)
            r.raise_for_status()
            return r
    else:
        r = requests.head(url, allow_redirects=True, timeout=15)
        if r.status_code >= 400:
            r.raise_for_status()
        return r

def _get_text(url: str) -> str:
    if _HTTPX:
        with httpx.Client(timeout=30.0, follow_redirects=True, headers={"User-Agent": "RegDataBridge/1.0"}) as c:
            r = c.get(url)
            r.raise_for_status()
            return r.text
    else:
        r = requests.get(url, timeout=30, headers={"User-Agent": "RegDataBridge/1.0"})
        r.raise_for_status()
        return r.text

def _extract_text(html: str, selector: Optional[str]) -> str:
    soup = BeautifulSoup(html, "html.parser")
    text_parts = []
    nodes = soup.select(selector) if selector else [soup]
    if not nodes:
        nodes = [soup]
    for n in nodes:
        for tag in n(["script", "style", "noscript", "nav", "header", "footer", "iframe"]):
            tag.decompose()
        t = n.get_text(separator="\n", strip=True)
        if t:
            text_parts.append(t)
    return "\n\n".join(text_parts).strip()

def check_for_update(selector: Optional[str] = None) -> dict:
    selector = selector or DEFAULT_SELECTOR
    new_signature = ""
    html = ""
    try:
        head_r = _head(TARGET_URL)
        etag = head_r.headers.get("ETag", "")
        lm = head_r.headers.get("Last-Modified", "")
        cl = head_r.headers.get("Content-Length", "")
        if etag or lm or cl:
            new_signature = f"etag={etag}|lm={lm}|cl={cl}"
        else:
            html = _get_text(TARGET_URL)
            new_signature = f"sha256={hashlib.sha256(html.encode('utf-8', 'ignore')).hexdigest()}"
    except Exception as e:
        return {
            "url": TARGET_URL,
            "updated": False,
            "diffSummary": f"Error getting signature: {e}",
            "error": str(e),
            "meta": {"content_type": "html", "selector_used": selector, "signature": "", "fetched_at": None},
        }

    old_signature = ""
    old_content = ""
    if SIGNATURE_FILE.exists():
        try:
            cached = json.loads(SIGNATURE_FILE.read_text("utf-8"))
            old_signature = cached.get("signature", "")
        except Exception:
            pass
    if CONTENT_FILE.exists():
        try:
            old_content = CONTENT_FILE.read_text("utf-8")
        except Exception:
            old_content = ""

    is_updated = (new_signature != old_signature)

    if is_updated:
        if not html:
            try:
                html = _get_text(TARGET_URL)
            except Exception as e:
                return {
                    "url": TARGET_URL,
                    "updated": False,
                    "diffSummary": f"Error downloading page: {e}",
                    "error": str(e),
                    "meta": {"content_type": "html", "selector_used": selector, "signature": new_signature, "fetched_at": None},
                }
        try:
            new_content = _extract_text(html, selector)
        except Exception as e:
            return {
                "url": TARGET_URL,
                "updated": False,
                "diffSummary": f"Error extracting HTML: {e}",
                "error": str(e),
                "meta": {"content_type": "html", "selector_used": selector, "signature": new_signature, "fetched_at": None},
            }

        SIGNATURE_FILE.write_text(json.dumps({"signature": new_signature}), encoding="utf-8")
        CONTENT_FILE.write_text(new_content, encoding="utf-8")

        return {
            "url": TARGET_URL,
            "updated": True,
            "diffSummary": "Content/signature changed",
            "new_content": new_content,
            "old_content": old_content,
            "meta": {
                "content_type": "html",
                "selector_used": selector,
                "signature": new_signature,
                "fetched_at": __import__("datetime").datetime.utcnow().isoformat() + "Z",
            },
        }

    return {
        "url": TARGET_URL,
        "updated": False,
        "diffSummary": "No change",
        "new_content": None,
        "old_content": old_content,
        "meta": {
            "content_type": "html",
            "selector_used": selector,
            "signature": new_signature,
            "fetched_at": __import__("datetime").datetime.utcnow().isoformat() + "Z",
        },
    }

if __name__ == "__main__":
    print(json.dumps(check_for_update(), indent=2))
