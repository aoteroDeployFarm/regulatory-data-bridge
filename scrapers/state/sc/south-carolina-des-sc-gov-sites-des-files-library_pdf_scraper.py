# Auto-generated by generate_scrapers_from_json.py (PDF)
from __future__ import annotations
from pathlib import Path
import hashlib, json, io

# HTTP client selection
try:
    import httpx
    _HTTPX = True
except Exception:  # pragma: no cover
    _HTTPX = False
    import requests

try:
    import pypdf
except Exception:
    pypdf = None

try:
    from pdfminer_high_level import extract_text as pdfminer_extract_text  # type: ignore
except Exception:
    try:
        from pdfminer.high_level import extract_text as pdfminer_extract_text  # type: ignore
    except Exception:
        pdfminer_extract_text = None

TARGET_URL = "https://des.sc.gov/sites/des/files/Library/Regulations/R.121-8.0_121-8.28.pdf"
CACHE_DIR = Path(__file__).parent / ".cache"
CACHE_DIR.mkdir(parents=True, exist_ok=True)
SIGNATURE_FILE = CACHE_DIR / "last_signature.json"
CONTENT_FILE = CACHE_DIR / "last_content.txt"

def _head(url: str):
    if _HTTPX:
        with httpx.Client(timeout=15.0, follow_redirects=True) as c:
            r = c.head(url)
            r.raise_for_status()
            return r
    else:
        r = requests.head(url, allow_redirects=True, timeout=15)
        if r.status_code >= 400:
            r.raise_for_status()
        return r

def _get_bytes(url: str) -> bytes:
    if _HTTPX:
        with httpx.Client(timeout=30.0, follow_redirects=True, headers={"User-Agent": "RegDataBridge/1.0"}) as c:
            r = c.get(url)
            r.raise_for_status()
            return r.content
    else:
        r = requests.get(url, timeout=30, headers={"User-Agent": "RegDataBridge/1.0"})
        r.raise_for_status()
        return r.content

def _extract_text_from_pdf_bytes(pdf_bytes: bytes) -> str:
    if pypdf:
        reader = pypdf.PdfReader(io.BytesIO(pdf_bytes))
        out = []
        for page in reader.pages:
            try:
                out.append(page.extract_text() or "")
            except Exception:
                continue
        return "\n".join([s for s in out if s]).strip()
    if pdfminer_extract_text:
        return (pdfminer_extract_text(io.BytesIO(pdf_bytes)) or "").strip()
    raise RuntimeError("No PDF text extraction library found (install pypdf or pdfminer.six)")

def check_for_update() -> dict:
    new_signature = ""
    pdf_bytes = b""
    try:
        head_r = _head(TARGET_URL)
        etag = head_r.headers.get("ETag", "")
        lm = head_r.headers.get("Last-Modified", "")
        cl = head_r.headers.get("Content-Length", "")
        if etag or lm or cl:
            new_signature = f"etag={etag}|lm={lm}|cl={cl}"
        else:
            pdf_bytes = _get_bytes(TARGET_URL)
            new_signature = f"sha256={hashlib.sha256(pdf_bytes).hexdigest()}"
    except Exception as e:
        return {
            "url": TARGET_URL,
            "updated": False,
            "diffSummary": f"Error getting PDF signature: {e}",
            "error": str(e),
            "meta": {"content_type": "pdf", "selector_used": None, "signature": "", "fetched_at": None},
        }

    old_signature = ""
    old_content = ""
    if SIGNATURE_FILE.exists():
        try:
            cached = json.loads(SIGNATURE_FILE.read_text("utf-8"))
            old_signature = cached.get("signature", "")
        except Exception:
            pass
    if CONTENT_FILE.exists():
        try:
            old_content = CONTENT_FILE.read_text("utf-8")
        except Exception:
            old_content = ""

    is_updated = (new_signature != old_signature)

    if is_updated:
        if not pdf_bytes:
            try:
                pdf_bytes = _get_bytes(TARGET_URL)
            except Exception as e:
                return {
                    "url": TARGET_URL,
                    "updated": False,
                    "diffSummary": f"Error downloading PDF: {e}",
                    "error": str(e),
                    "meta": {"content_type": "pdf", "selector_used": None, "signature": new_signature, "fetched_at": None},
                }
        try:
            new_content = _extract_text_from_pdf_bytes(pdf_bytes)
        except Exception as e:
            return {
                "url": TARGET_URL,
                "updated": False,
                "diffSummary": f"Error extracting text from PDF: {e}",
                "error": str(e),
                "meta": {"content_type": "pdf", "selector_used": None, "signature": new_signature, "fetched_at": None},
            }

        SIGNATURE_FILE.write_text(json.dumps({"signature": new_signature}), encoding="utf-8")
        CONTENT_FILE.write_text(new_content, encoding="utf-8")

        return {
            "url": TARGET_URL,
            "updated": True,
            "diffSummary": "PDF signature/content changed",
            "new_content": new_content,
            "old_content": old_content,
            "meta": {
                "content_type": "pdf",
                "selector_used": None,
                "signature": new_signature,
                "fetched_at": __import__("datetime").datetime.utcnow().isoformat() + "Z",
            },
        }

    return {
        "url": TARGET_URL,
        "updated": False,
        "diffSummary": "No change",
        "new_content": None,
        "old_content": old_content,
        "meta": {
            "content_type": "pdf",
            "selector_used": None,
            "signature": new_signature,
            "fetched_at": __import__("datetime").datetime.utcnow().isoformat() + "Z",
        },
    }

if __name__ == "__main__":
    print(json.dumps(check_for_update(), indent=2))
